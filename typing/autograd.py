# -*- coding: utf-8 -*-
"""Autograd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rsTJFrmN2WD7oIZgk7sjBtAoS6SdRrei
"""

import numpy as np

"""Напишем собственный мини-pytorch!

Любая уважающая себя библиотека с нейросетями умеет в автоматическое дифференцирование. Это значит, что она умеет по заданным функциям считать производные на обратном проходе.

Например, пусть у нас есть функция $f = (x+y) \cdot z$:  
![graph](https://image.ibb.co/mWM0Lx/1_6o_Utr7_ENFHOK7_J4l_XJtw1g.png =500x)

Она разбивается на набор промежуточных операций: $q = x+y, f = q \cdot z$.

Мы хотим посчитать производные $\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z}$. Воспользуемся chain rule:

$$\frac{\partial f}{\partial x} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial x} = z \cdot 1.$$

Таким образом, для вычисления производной по $x$ нам нужно сначала посчитать производную по $q$. Обратный проход как раз и состоит в том, чтобы считать производные по очереди, используя chain rule.

---

Собственно, напишем свою реализацию всего этого.

Пусть у нас есть два типа тензоров - `FloatTensor` и `LongTensor`.
"""

class FloatTensor:
  def __init__(self, array):
    self.array = np.array(array, dtype='float32', ndmin=1)
    self.shape = self.array.shape
    
  def __add__(self, other):
    return FloatTensor(self.array + other.array)

  def __sub__(self, other):
    return FloatTensor(self.array - other.array)
  
  def __mul__(self, other):
    return FloatTensor(self.array * other.array)
  
  def __pow__(self, p):
    return FloatTensor(self.array ** p)
  
  def mean(self, axis):
    return FloatTensor(self.array.mean(axis))
  
  def __repr__(self):
    return '{}\nFloatTensor with shape {}'.format(self.array, self.shape)
  
class LongTensor:
  def __init__(self, array):
    self.array = np.array(array, dtype='int64', ndmin=1)
    self.shape = self.array.shape
    
  def __add__(self, other):
    return LongTensor(self.array + other.array)

  def __sub__(self, other):
    return LongTensor(self.array - other.array)

  def __mul__(self, other):
    return LongTensor(self.array * other.array)
  
  def __pow__(self, p):
    return LongTensor(self.array ** p)
  
  def mean(self, axis):
    return LongTensor(self.array.mean(axis))
  
  def __repr__(self):
    return '{}\LongTensor with shape {}'.format(self.array, self.shape)

"""Напишем `Variable` - обертку над тензорами, которая будет строить (неявно) граф вычислений и делать обратный шаг.

Рассмотрим, например, сложение. Нужно найти `Variable` $z = x + y$. Тогда будем запоминать, во-первых, сами $x$ и $y$ в $z$. А во-вторых, нужно помнить, что $\frac{\partial z}{\partial x} = 1$ и $\frac{\partial z}{\partial y} = 1$:
```python
  def __add__(self, other):
    return Variable(self.data + other.data,
                    childs = [self, other],
                    local_grads = [np.array([1]), np.array([1])])
  
```

Нужно реализовать такие же операции и для вычитания, умножения, возведения в степень и взятия среднего (для начала).
"""

class Variable:
  def __init__(self, data, childs=None, local_grads=np.array([1])):
    self.data = data
    self.childs = childs
    self.local_grads = local_grads
    self.zero_grad()
  
  def zero_grad(self):
    self.grad = FloatTensor(np.zeros_like(self.data.array))
  
  def __add__(self, other):
    return Variable(self.data + other.data,
                    childs = [self, other],
                    local_grads = [np.array([1]), np.array([1])])

  def __sub__(self, other):
    return Variable(self.data - other.data,
                    childs = [self, other],
                    local_grads = [np.array([1]), np.array([-1])])
  
  def __mul__(self, other):
    return Variable(self.data * other.data,
                    childs = [self, other],
                    local_grads = [np.array(other.data.array), np.array(self.data.array)])

  def __pow__(self, p):
    return Variable(self.data ** p,
                    childs = [self],
                    local_grads = [np.array(p * self.data.array ** (p - 1))])
  
  def mean(self, axis):
    return Variable(self.data.mean(axis),
                    childs = [self],
                    local_grads = [np.array(np.ones(self.data.shape) / self.data.shape[axis])])
  
  def backward(self, gradient=np.array([1])):
    if self.childs:
      for child, local_grad in zip(self.childs, self.local_grads):
        child.backward(local_grad * gradient)
    axes = tuple([i for i, axis in enumerate(gradient.shape) 
                  if i < len(self.grad.shape) or self.grad.shape[i] == 1])
    self.grad.array += np.sum(gradient, axis=axes)
  
  def __repr__(self):
    return 'Variable:\n{}'.format(self.data)

"""При чём тут типизация? А при том, что мы пользуемся `self.data + other.data`, надеясь, что `data` содержит что-то, умееющее складываться (т.е. реализующее `__add__`).

Мы пользуемся утиностью типизации питона - всё, что удовлетворяет этому интерфейсу, можно передать в качестве `data`. С другой стороны, мы работаем с динамической типизацией - никаких проверок, действительно ли передаваемое полностью удовлетворяет интерфейсу, не происходит: нет, значит, упадём по ходу дела.
 
---
 
Напишем простую линейную регрессию для проверки:
"""

from sklearn.datasets import load_boston
import matplotlib.pyplot as plt
from IPython import display

boston = load_boston()
plt.scatter(boston.data[:, -1], boston.target)

"""Создаем переменные:"""

w = Variable(FloatTensor(np.zeros(1)))
b = Variable(FloatTensor(np.zeros(1)))

x = Variable(FloatTensor(boston.data[:,-1] / 10))
y = Variable(FloatTensor(boston.target))

"""Мы пишем линейную регрессию, значит, (в данном случае) нужно подобрать прямую, которая будет хорошо проходить по точкам на графике выше"""

y_pred = w * x  + b

"""Считаем простое средне-квадратичное отклонение - и делаем `backward`"""

loss = ((y_pred - y)**2).mean(0)
loss.backward()

"""Должны посчитаться производные"""

print('dL/dw = ', w.grad)
print('dL/db = ', b.grad)

"""Оптимизируем с помощью градиентного спуска:
$$\theta^{(t+1)} = \theta^{(t)} - \eta \nabla_\theta L(\theta)$$

$L$ - это функция потерь, $\eta$ - learning rate.
"""

from IPython.display import clear_output
import time

for i in range(200):
    y_pred = w * x  + b
    loss = ((y_pred - y)**2).mean(0)
    loss.backward()

    w.data -= FloatTensor(0.05) * w.grad
    b.data -= FloatTensor(0.05) * b.grad
    
    # Зануляем градиенты
    w.zero_grad()
    b.zero_grad()
    
    if (i+1) % 5 == 0:
        clear_output(True)
        plt.scatter(x.data.array, y.data.array)
        plt.scatter(x.data.array, y_pred.data.array, color='orange', linewidth=5)
        plt.show()
        # Нужно специально для colab'а - он не успевает перерисовывать иначе. В обычном ноутбуке лучше убрать
        time.sleep(1)

        print("loss = ", loss.data.array)